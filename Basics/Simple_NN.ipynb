{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# An Introduction to Neural Networks\n",
    "\n",
    "A simple explanation \n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Building Blocks: Neurons](#1-building-blocks-neurons)\n",
    "2. [Combining Neurons into a Neural Network](#2-combining-neurons-into-a-neural-network)\n",
    "3. [Training a Neural Network, Part 1](#3-training-a-neural-network-part-1)\n",
    "4. [Training a Neural Network, Part 2](#4-training-a-neural-network-part-2)\n",
    "5. [Now What?](#now-what)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Building Blocks: Neurons\n",
    "\n",
    "First, we have to talk about neurons, the basic unit of a neural network. A neuron takes inputs, does some math with them, and produces one output. Here's what a 2-input neuron looks like:\n",
    "\n",
    "![Neuron Diagram](images/network.svg)\n",
    "\n",
    "Three things are happening here:\n",
    "\n",
    "1. **Weighted Sum**: Each input is multiplied by a weight:\n",
    "   - \\( x_1 \\rightarrow x_1 \\times w_1 \\)\n",
    "   - \\( x_2 \\rightarrow x_2 \\times w_2 \\)\n",
    "\n",
    "2. **Adding Bias**: The weighted inputs are added together with a bias \\( b \\):\n",
    "   - \\( (x_1 \\times w_1) + (x_2 \\times w_2) + b \\)\n",
    "\n",
    "3. **Activation Function**: The sum is passed through an activation function:\n",
    "   - \\( y = f(x_1 \\times w_1 + x_2 \\times w_2 + b) \\)\n",
    "\n",
    "The activation function is used to turn an unbounded input into an output that has a nice, predictable form. A commonly used activation function is the **sigmoid function**:\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$\n",
    "\n",
    "The sigmoid function outputs numbers in the range (0, 1). You can think of it as compressing \\((-∞, +∞)\\) to \\((0, 1)\\)—big negative numbers become ~0, and big positive numbers become ~1.\n",
    "\n",
    "### A Simple Example\n",
    "\n",
    "Assume we have a 2-input neuron that uses the sigmoid activation function and has the following parameters:\n",
    "\n",
    "- Weights: \\( w = [0, 1] \\) (i.e., \\( w_1 = 0, w_2 = 1 \\))\n",
    "- Bias: \\( b = 4 \\)\n",
    "- Input: \\( x = [2, 3] \\)\n",
    "\n",
    "We compute the neuron's output:\n",
    "\n",
    "1. **Weighted Sum with Bias**:\n",
    "\n",
    "   $$\n",
    "   \\begin{align*}\n",
    "   w \\cdot x + b &= (w_1 x_1 + w_2 x_2) + b \\\\\n",
    "                 &= (0 \\times 2 + 1 \\times 3) + 4 \\\\\n",
    "                 &= 7\n",
    "   \\end{align*}\n",
    "   $$\n",
    "\n",
    "2. **Activation**:\n",
    "\n",
    "   $$\n",
    "   y = f(w \\cdot x + b) = \\sigma(7) \\approx 0.999\n",
    "   $$\n",
    "\n",
    "The neuron outputs approximately **0.999** given the inputs \\( x = [2, 3] \\).\n",
    "\n",
    "### Coding a Neuron\n",
    "\n",
    "We'll use NumPy to implement the neuron:\n",
    "\n"
   ],
   "id": "3e203f1045a70aad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-09T23:35:13.512256Z",
     "start_time": "2024-11-09T23:35:13.245253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "# Example parameters and inputs\n",
    "weights = np.array([0, 1])  # w1 = 0, w2 = 1\n",
    "bias = 4                    # b = 4\n",
    "neuron = Neuron(weights, bias)\n",
    "\n",
    "# Example input\n",
    "x = np.array([2, 3])        # x1 = 2, x2 = 3\n",
    "print(neuron.feedforward(x))  "
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Combining Neurons into a Neural Network\n",
    "\n",
    "A neural network is nothing more than a bunch of neurons connected together. Here's what a simple neural network might look like:\n",
    "\n",
    "![Simple Neural Network](images/simple_neural_network.png)\n",
    "## layers of a Neural Network\n",
    "A neural network is formed by connecting neurons together. For example, a simple network might have:\n",
    "\n",
    "- **Input Layer**: Takes in inputs.\n",
    "- **Hidden Layer**: Processes the inputs using neurons.\n",
    "- **Output Layer**: Produces the final output.\n",
    "\n",
    "### Example Neural Network Structure\n",
    "A network with:\n",
    "- 2 input features,\n",
    "- 1 hidden layer with 2 neurons,\n",
    "- 1 output neuron.\n",
    "\n",
    "### Example Neural Network Implementation\n",
    "This network has:\n",
    "\n",
    "- **2 inputs**.\n",
    "- A **hidden layer** with **2 neurons** (\\( h_1 \\) and \\( h_2 \\)).\n",
    "- An **output layer** with **1 neuron** (\\( o_1 \\)).\n",
    "\n",
    "Notice that the inputs for \\( o_1 \\) are the outputs from \\( h_1 \\) and \\( h_2 \\)—that's what makes this a network.\n",
    "\n",
    "\n",
    "\n",
    "### An Example: Feedforward\n",
    "\n",
    "Let's use the network pictured above and assume:\n",
    "\n",
    "- All neurons have the same weights \\( w = [0, 1] \\).\n",
    "- The same bias \\( b = 0 \\).\n",
    "- The same sigmoid activation function.\n",
    "\n",
    "Let \\( h_1, h_2, o_1 \\) denote the outputs of the neurons they represent.\n",
    "\n",
    "**Input**:\n",
    "\n",
    "- \\( x = [2, 3] \\)\n",
    "\n",
    "#### Calculations:\n",
    "\n",
    "1. **Compute \\( h_1 \\) and \\( h_2 \\)**:\n",
    "\n",
    "   $$\n",
    "   \\begin{align*}\n",
    "   h_1 &= f(w \\cdot x + b) \\\\\n",
    "       &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "       &= f(0 \\times 2 + 1 \\times 3 + 0) \\\\\n",
    "       &= f(3) \\\\\n",
    "       &= 0.9526 \\\\\n",
    "   \\\\\n",
    "   h_2 &= f(w \\cdot x + b) \\\\\n",
    "       &= f(0 \\times 2 + 1 \\times 3 + 0) \\\\\n",
    "       &= f(3) \\\\\n",
    "       &= 0.9526\n",
    "   \\end{align*}\n",
    "   $$\n",
    "\n",
    "2. **Compute \\( o_1 \\)**:\n",
    "\n",
    "   $$\n",
    "   \\begin{align*}\n",
    "   o_1 &= f(w \\cdot [h_1, h_2] + b) \\\\\n",
    "       &= f(w_1 h_1 + w_2 h_2 + b) \\\\\n",
    "       &= f(0 \\times 0.9526 + 1 \\times 0.9526 + 0) \\\\\n",
    "       &= f(0.9526) \\\\\n",
    "       &= 0.7216\n",
    "   \\end{align*}\n",
    "   $$\n",
    "\n",
    "**Result**: The output of the neural network for input \\( x = [2, 3] \\) is approximately **0.7216**.\n",
    "\n",
    "### Coding a Neural Network: Feedforward\n",
    "\n",
    "Let's implement feedforward for our neural network."
   ],
   "id": "243fdf56fbbe9007"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class OurNeuralNetwork:\n",
    "    \"\"\"\n",
    "    A neural network with:\n",
    "      - 2 inputs\n",
    "      - a hidden layer with 2 neurons (h1, h2)\n",
    "      - an output layer with 1 neuron (o1)\n",
    "    Each neuron has the same weights and bias:\n",
    "      - w = [0, 1]\n",
    "      - b = 0\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        weights = np.array([0, 1])\n",
    "        bias = 0\n",
    "\n",
    "        # The Neuron class here is from the previous section\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "\n",
    "        # The inputs for o1 are the outputs from h1 and h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "\n",
    "        return out_o1   \n",
    "    "
   ],
   "id": "9fec5f34bbe50c7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Training a Neural Network, Part 1\n",
    "\n",
    "Say we have the following measurements:\n",
    "\n",
    "| Name     | Weight (lb) | Height (in) | Gender |\n",
    "|----------|-------------|-------------|--------|\n",
    "| Alice    | 133         | 65          | F      |\n",
    "| Bob      | 160         | 72          | M      |\n",
    "| Charlie  | 152         | 70          | M      |\n",
    "| Diana    | 120         | 60          | F      |\n",
    "\n",
    "Let's train our network to predict someone's gender given their weight and height:\n",
    "\n",
    "![Neural Network for Gender Prediction](images/gender_prediction_network.png)\n",
    "\n",
    "We'll represent Male with a **0** and Female with a **1**, and we'll also shift the data to make it easier to use:\n",
    "\n",
    "| Name     | Weight (minus 135) | Height (minus 66) | Gender |\n",
    "|----------|--------------------|-------------------|--------|\n",
    "| Alice    | -2                 | -1                | 1      |\n",
    "| Bob      | 25                 | 6                 | 0      |\n",
    "| Charlie  | 17                 | 4                 | 0      |\n",
    "| Diana    | -15                | -6                | 1      |\n",
    "\n",
    "*Note*: We shifted the weights and heights by subtracting 135 and 66, respectively, to center the data around zero.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "Before we train our network, we need a way to quantify how \"good\" it's doing so that it can try to do \"better\". That's what the **loss function** is for.\n",
    "\n",
    "We'll use the **mean squared error (MSE)** loss:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_{\\text{true}} - y_{\\text{pred}})^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\( n \\) is the number of samples.\n",
    "- \\( y_{\\text{true}} \\) is the true value of the output (the correct answer).\n",
    "- \\( y_{\\text{pred}} \\) is the predicted value from our network.\n",
    "\n",
    "### An Example Loss Calculation\n",
    "\n",
    "Let's say our network always outputs **0** (i.e., it predicts everyone is Male). What would our loss be?\n",
    "\n",
    "| Name     | \\( y_{\\text{true}} \\) | \\( y_{\\text{pred}} \\) | \\( (y_{\\text{true}} - y_{\\text{pred}})^2 \\) |\n",
    "|----------|-----------------------|-----------------------|---------------------------------------------|\n",
    "| Alice    | 1                     | 0                     | 1                                           |\n",
    "| Bob      | 0                     | 0                     | 0                                           |\n",
    "| Charlie  | 0                     | 0                     | 0                                           |\n",
    "| Diana    | 1                     | 0                     | 1                                           |\n",
    "\n",
    "Compute MSE:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{4} (1 + 0 + 0 + 1) = 0.5\n",
    "$$\n",
    "\n",
    "### Code: MSE Loss\n",
    "\n",
    "Here's some code to calculate loss:\n",
    "\n",
    "\n"
   ],
   "id": "9a0f6fe794b13629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## 4. Training a Neural Network, Part 2\n",
    "import numpy as np\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "# Example usage\n",
    "y_true = np.array([1, 0, 0, 1])  # True genders\n",
    "y_pred = np.array([0, 0, 0, 0])  # Predicted genders (all Male)\n",
    "\n",
    "print(\"MSE Loss:\", mse_loss(y_true, y_pred))  # Output: 0.5"
   ],
   "id": "e4c59dc64524fba1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
