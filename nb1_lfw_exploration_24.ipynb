{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZuIkLpjk-WzE"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalmashooq/ML_Practice/blob/master/nb1_lfw_exploration_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Colab 101"
      ],
      "metadata": {
        "id": "ssYTZWx-sZQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 2\n",
        "b = 3\n",
        "a + b"
      ],
      "metadata": {
        "id": "124K51xGRYBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "fxIKWH_4Rc5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "gAD_htvLRTrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tpu-info"
      ],
      "metadata": {
        "id": "Nnk9uGchIv-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ8rdK9Ocl62"
      },
      "source": [
        "# Setup\n",
        "Note: before running any cell, please check that your Runtime has GPU!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6prrunAaEAE6"
      },
      "source": [
        "## Import modules and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRJARmySx2u8"
      },
      "source": [
        "#@title Authenticate with Google Acoount and do imports { display-mode: \"form\" }\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "jaRr1LWH-Ws6"
      },
      "source": [
        "#@title Import standard machine learning and data science modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import metrics\n",
        "from scipy.spatial import distance\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Import zoom function\n",
        "# from keras_preprocessing.image import random_zoom\n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from matplotlib.image import pil_to_array, imread\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Keras modules\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import image_dataset_from_directory, array_to_img, img_to_array, load_img\n",
        "from keras.layers import RandomZoom\n",
        "from keras import layers\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Input, Lambda, AveragePooling2D, Activation, PReLU, ReLU\n",
        "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, TerminateOnNaN\n",
        "from keras.optimizers import SGD, Adam\n",
        "import keras.backend as K\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "KOAYcKprJGJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.__version__"
      ],
      "metadata": {
        "id": "GDrwlF3_JS1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcciiRAPByO5"
      },
      "source": [
        "#@title Helper functions: image processing and useful plots { display-mode: \"form\" }\n",
        "# Google Drive upload/download helpers\n",
        "def drive_upload_file(full_filename):\n",
        "  filename = os.path.basename(full_filename)\n",
        "  file_to_upload = drive.CreateFile({'title': filename})\n",
        "  file_to_upload.SetContentFile(full_filename)\n",
        "  file_to_upload.Upload()\n",
        "\n",
        "def drive_download_file(file_id, local_path='./'):\n",
        "  # A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  downloaded.FetchMetadata()\n",
        "  fn = downloaded.metadata.get('originalFilename')\n",
        "  full_fn = os.path.join(local_path, fn)\n",
        "  downloaded.GetContentFile(full_fn)\n",
        "  return full_fn\n",
        "\n",
        "# Dataset reading helpers\n",
        "def filter_df(df, min_images_count=0):\n",
        "  df = df.sort_values('images', ascending=False)\n",
        "  return df[df.images >= min_images_count]\n",
        "\n",
        "# Undo ImageNet preprocessing to show images from batch generator\n",
        "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32)  # RGB\n",
        "de_preproc = lambda x: np.clip((x[..., ::-1]+vgg_mean)/255., 0, 1)\n",
        "\n",
        "# Visualization helpers\n",
        "# Images root dir\n",
        "img_root_dir = 'input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n",
        "\n",
        "# equal probabilities\n",
        "equal_apriori = 0.5\n",
        "\n",
        "# number of thresholds\n",
        "num_thresholds = 100\n",
        "# generate a list of  n thresholds between 0.0 and 1.0\n",
        "thresholds = [i/num_thresholds for i in range(num_thresholds)]\n",
        "\n",
        "def plot_scores(imposter, genuine):\n",
        "  \"\"\" Plot the scores of the genuine and imposters \"\"\"\n",
        "\n",
        "  # Draws a histogram to show score frequencies with values.\n",
        "  plt.hist(imposter, facecolor='g', alpha=0.50, label='Imposter')\n",
        "  plt.hist(genuine, facecolor='y', alpha=0.50, label='Genuine')\n",
        "\n",
        "  # Adding labels and titles to the plot\n",
        "  plt.xlabel('Score')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.title('Score Distribution')\n",
        "  plt.grid(True)\n",
        "\n",
        "  # draw the key/legend\n",
        "  plot_legends()\n",
        "\n",
        "  # show the plot\n",
        "  show_plot()\n",
        "\n",
        "def calculate_cost(imposter, genuine):\n",
        "  \"\"\" For both users, calculates a confusion matrix and then calculates cost per threshold \"\"\"\n",
        "\n",
        "  # generate n number of thresholds\n",
        "\n",
        "  far = []\n",
        "  frr = []\n",
        "  cost = []\n",
        "\n",
        "  # for each threshold, calculate confusion matrix.\n",
        "  for t in thresholds:\n",
        "\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "\n",
        "    # go through imposters\n",
        "    for score in imposter:\n",
        "\n",
        "      if score >= t:\n",
        "        # imposter passes as a genuine user\n",
        "        FP += 1\n",
        "      else:\n",
        "        # imposter correctly rejected\n",
        "        TN += 1\n",
        "\n",
        "    for score in genuine:\n",
        "      if score >= t:\n",
        "        # genuine user correctly identified\n",
        "        TP += 1\n",
        "      else:\n",
        "        # genuine user incorrectly rejected\n",
        "        FN += 1\n",
        "\n",
        "    far_current = float(FP) / float(len(imposter))\n",
        "    frr_current = float(FN) / float(len(genuine))\n",
        "\n",
        "    # calculate our false accept rate(FAR) and add to list\n",
        "    far.append(far_current)\n",
        "\n",
        "    # calculate our false reject rate(FRR) and add to list\n",
        "    frr.append(frr_current)\n",
        "\n",
        "  return far, frr\n",
        "\n",
        "def plot_DET_with_EER(far, frr, far_optimum, frr_optimum):\n",
        "  \"\"\" Plots a DET curve with the most suitable operating point based on threshold values\"\"\"\n",
        "\n",
        "  # Plot the DET curve based on the FAR and FRR values\n",
        "  plt.plot(far, frr, linestyle=\"--\", linewidth=4, label=\"DET Curve\")\n",
        "\n",
        "  # Plot the optimum point on the DET Curve\n",
        "  plt.plot(far_optimum,frr_optimum, \"ro\", label=\"Suitable Operating Point\")\n",
        "\n",
        "  # Draw the default DET Curve from 1-1\n",
        "  plt.plot([1.0,0.0], [0.0,1.0],\"k--\")\n",
        "\n",
        "  # Draws the key/legend\n",
        "  plot_legends()\n",
        "\n",
        "  # Displays plots\n",
        "  show_plot()\n",
        "\n",
        "def plot_FAR_vs_FRR(far, frr):\n",
        "  # Plot FAR and FRR\n",
        "  plt.plot(thresholds, far, 'g-', label='FAR curve')\n",
        "  plt.plot(thresholds, frr, 'b-', label='FRR curve')\n",
        "\n",
        "  # Draws the key/legend\n",
        "  plot_legends()\n",
        "\n",
        "  # Displays plots\n",
        "  show_plot()\n",
        "\n",
        "def find_EER(far, frr):\n",
        "  \"\"\" Returns the most optimal FAR and FRR values \"\"\"\n",
        "\n",
        "  # The lower the equal error rate value,\n",
        "  # the higher the accuracy of the biometric system.\n",
        "\n",
        "  # smallest value is most accurate\n",
        "  far = np.array(far)\n",
        "  frr = np.array(frr)\n",
        "  delta = np.abs(far - frr)\n",
        "  t = np.argmin(delta)\n",
        "  far_optimum = far[t]\n",
        "  frr_optimum = frr[t]\n",
        "  threshold_optimum = thresholds[t]\n",
        "\n",
        "  return far_optimum, frr_optimum, threshold_optimum\n",
        "\n",
        "def plot_legends():\n",
        "  legend = plt.legend(loc='upper center', shadow=True, fontsize='x-large')\n",
        "  legend.get_frame().set_facecolor('#ffffff')\n",
        "\n",
        "def show_plot():\n",
        "  plt.show()\n",
        "\n",
        "def extract_template(image_paths, model, target_size=(224, 224), batch_size=32):\n",
        "  \"\"\"\n",
        "  Extract image template from a filename list using a Keras model and tf.data.Dataset.\n",
        "\n",
        "  Args:\n",
        "    image_paths: A list of image filenames.\n",
        "    model: Keras model with a predict method.\n",
        "    target_size: Tuple (height, width) for resizing images.\n",
        "    batch_size: Batch size for prediction.\n",
        "\n",
        "  Returns:\n",
        "    A list of model prediction results.\n",
        "  \"\"\"\n",
        "\n",
        "  def preprocess_image(image_path):\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (256, 256))\n",
        "    img = zoom_image(img)\n",
        "    # img = preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "  zoom_image = keras.Sequential([\n",
        "    keras.layers.RandomZoom((-0.5, -0.5)),\n",
        "    keras.layers.Resizing(target_size[0], target_size[1]),\n",
        "    keras.layers.Rescaling(scale=1./255)\n",
        "  ])\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "  dataset = dataset.map(preprocess_image)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "  predictions = model.predict(dataset)\n",
        "\n",
        "  return predictions.tolist()\n",
        "\n",
        "def name_to_image_path(root_dir, name, image_num):\n",
        "  return f'{root_dir}/{name}/{name}_{image_num:04d}.jpg'\n",
        "\n",
        "def evaluate_model(model, pairs_file='./input/lfw-dataset/course-pairsDevTest.csv'):\n",
        "  # Cut our model at the 'embedding' layer level and convert it to template extractor\n",
        "  embedding_out = model.get_layer('face_embedding').output\n",
        "  template_extrator = Model(inputs=[input_layer], outputs=[embedding_out])\n",
        "\n",
        "  # Read pairs matched and mismatched for dev dataset\n",
        "  print('Preparing stats from dev set')\n",
        "  test_pairs = pd.read_csv(pairs_file)\n",
        "  test_pairs['img_fn1'] = test_pairs.apply(lambda row: name_to_image_path(img_root_dir, row['name1'], row['imagenum1']), axis=1)\n",
        "  test_pairs['img_fn2'] = test_pairs.apply(lambda row: name_to_image_path(img_root_dir, row['name2'], row['imagenum2']), axis=1)\n",
        "\n",
        "  # Apply the template model to all images\n",
        "  test_pairs['template1'] = extract_template(test_pairs['img_fn1'], template_extrator, target_size)\n",
        "  test_pairs['template2'] = extract_template(test_pairs['img_fn2'], template_extrator, target_size)\n",
        "  test_pairs['cos_distance'] = test_pairs.apply(lambda row: distance.cosine(row['template1'], row['template2'])/2., axis=1)  # cos distance rescaled to (0,1)\n",
        "\n",
        "  match_scores = test_pairs[test_pairs.match_pair==1]['cos_distance']\n",
        "  mismatch_scores = test_pairs[test_pairs.match_pair==0]['cos_distance']\n",
        "\n",
        "  # Plot model's stats\n",
        "  genuine = match_scores.values\n",
        "  imposter = mismatch_scores.values\n",
        "\n",
        "  far, frr = calculate_cost(imposter, genuine)\n",
        "  far_optimum, frr_optimum, err_threshold = find_EER(far, frr)\n",
        "\n",
        "  plot_scores(imposter, genuine)\n",
        "  plot_DET_with_EER(far, frr, far_optimum, frr_optimum)\n",
        "  plot_FAR_vs_FRR(far, frr)\n",
        "  print(f'EER at threshold: {err_threshold}')\n",
        "\n",
        "  # Now let's calculate accuracy for test set\n",
        "  test_pairs['pred_match_pair'] = test_pairs['cos_distance'] < err_threshold\n",
        "  test_pairs['pred_match_pair'] = test_pairs['pred_match_pair'].astype(int)\n",
        "\n",
        "  print(f'At threshold {err_threshold} accuracy score is {accuracy_score(test_pairs.match_pair.values, test_pairs.pred_match_pair.values):.4f}')\n",
        "  return test_pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcpaEoSqEtcI"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuWvtqe7IeFt"
      },
      "source": [
        "## Download and unpack LFW files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9c4ec24b1b9432ae9e38e48f1f8ed12a6c7df7c6",
        "id": "FFnDLnvb-WtB"
      },
      "source": [
        "# Prepare Labelled Faces in the Wild dataset\n",
        "!mkdir -p input/lfw-dataset\n",
        "\n",
        "# Download LFW file (drive id is '14ra9GYFzdyeubZ5qtSDaDAbFDKPCjdAD')\n",
        "file_id = '14ra9GYFzdyeubZ5qtSDaDAbFDKPCjdAD'\n",
        "drive_download_file(file_id, local_path='./input/')\n",
        "\n",
        "# Unpack zip files\n",
        "!7z x ./input/lfw-dataset.zip -o./input/lfw-dataset -aoa\n",
        "!7z x ./input/lfw-dataset/lfw-deepfunneled.zip -o./input/lfw-dataset/lfw-deepfunneled -aoa\n",
        "\n",
        "# Clean temp files\n",
        "!rm -r ./input/lfw-dataset/lfw-deepfunneled/__MACOSX/ ./input/lfw-dataset/__MACOSX/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtYx8__JCf5Y"
      },
      "source": [
        "!ls -lh **/**/**"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-7x4FXJFs-F"
      },
      "source": [
        "## Copy images into train-validation directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "6ef63e7bec9a96c73e2c25415986834eea06db9b",
        "id": "rH6Z7-yg-WtT"
      },
      "source": [
        "# Load LFW labels and keep only people with > min_images_count images\n",
        "df_train = filter_df(pd.read_csv('./input/lfw-dataset/peopleDevTrain.csv'), min_images_count=20)\n",
        "df_train.head(), len(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0754253671d33dd7c9f75e5f9e6babce5e621683",
        "id": "xsG9lYq5-Wte"
      },
      "source": [
        "# Prepare a list of all images for names in train list\n",
        "all_train = []\n",
        "for name in df_train.name.values:\n",
        "    imgs_for_name = glob(f'./input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/{name}/*.jpg')\n",
        "    all_train += [{'name': name, 'filename': fn} for fn in imgs_for_name]\n",
        "\n",
        "# Train-validation split\n",
        "df_train = pd.DataFrame(all_train)\n",
        "df_train, df_val = train_test_split(df_train, train_size=0.8, stratify=df_train.name.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "e379e045e1f19bd6877aa3bb5c1b788770941b76",
        "id": "fG7FNczp-Wt4"
      },
      "source": [
        "# Check split lenght\n",
        "len(df_train), len(df_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4UWrzRUDE5F"
      },
      "source": [
        "# Create directories structure\n",
        "root_path = 'input/lfw-train-test-split'\n",
        "\n",
        "weights_path = './weights'\n",
        "logs_path = f'{root_path}/logs'\n",
        "os.makedirs(weights_path, exist_ok=True)\n",
        "os.makedirs(logs_path, exist_ok=True)\n",
        "\n",
        "train_path = f'{root_path}/train/'\n",
        "validation_path = f'{root_path}/validation/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "343c36a2c9f07279e0bebc1a50de455f4c26eece",
        "id": "5GTLeRai-WuB"
      },
      "source": [
        "# Make 'name' directories in the train-valid dirs\n",
        "shutil.rmtree(train_path, ignore_errors=True)\n",
        "shutil.rmtree(validation_path, ignore_errors=True)\n",
        "os.makedirs(train_path, exist_ok=True)\n",
        "os.makedirs(validation_path, exist_ok=True)\n",
        "\n",
        "for name in df_train.name.values:\n",
        "    os.makedirs(os.path.join(train_path, name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(validation_path, name), exist_ok=True)\n",
        "\n",
        "print(f\"Created directories: \\n{train_path}, \\n{validation_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "53942c2a50bbe51ab01b528168b2053101ca93be",
        "id": "eFegYAdZ-WuL"
      },
      "source": [
        "# Copy to train dir\n",
        "for i, row in tqdm(df_train.iterrows()):\n",
        "    shutil.copy(row['filename'], os.path.join(train_path, row['name']))\n",
        "\n",
        "# Copy to validation dir\n",
        "for i, row in tqdm(df_val.iterrows()):\n",
        "    shutil.copy(row['filename'], os.path.join(validation_path, row['name']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "cd78090ff47dceda08f48585dd52aeebe2311646",
        "_kg_hide-output": true,
        "id": "wUD4AjdU-Wue"
      },
      "source": [
        "# Show some images\n",
        "imgs_fn = glob(f'{train_path}/**/*.jpg', recursive=True)\n",
        "for fn in np.random.choice(imgs_fn, size=3):\n",
        "    img = Image.open(fn)\n",
        "    print(fn, img.height, img.width)\n",
        "    display(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "4c84f6b5a671a037087794282596e8d6e49698d6",
        "id": "SBUs2HNk-Wui"
      },
      "source": [
        "# Train models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFIj5A36GNFe"
      },
      "source": [
        "## Image data generators"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {train_path}/*/*.jpg"
      ],
      "metadata": {
        "id": "nS-QYKfHknyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "batch_size = 32*3\n",
        "target_size = (128, 128)\n",
        "n_count = 3"
      ],
      "metadata": {
        "id": "mNtF7KKaTBBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_aug = keras.Sequential([\n",
        "    keras.layers.RandomZoom((-0.45, -0.55)),\n",
        "    keras.layers.RandomFlip(mode=\"horizontal\"),\n",
        "    keras.layers.RandomBrightness(0.2),\n",
        "    keras.layers.RandomContrast(0.2),\n",
        "    keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    keras.layers.Resizing(target_size[0], target_size[1]),\n",
        "    keras.layers.Rescaling(scale=1./255)\n",
        "])\n",
        "\n",
        "valid_img_aug = keras.Sequential([\n",
        "    keras.layers.RandomZoom((-0.5, -0.5)),\n",
        "    keras.layers.Resizing(target_size[0], target_size[1]),\n",
        "    keras.layers.Rescaling(scale=1./255)\n",
        "])"
      ],
      "metadata": {
        "id": "EgiTKxmS25UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image, label, img_aug):\n",
        "    image = img_aug(image)\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "tN1YOe6eKyJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train data generator\n",
        "train_dataset =  keras.utils.image_dataset_from_directory(\n",
        "      train_path,\n",
        "      labels='inferred',\n",
        "      label_mode='categorical',\n",
        "      batch_size=batch_size,\n",
        "      image_size=(256, 256)\n",
        "  )\n",
        "\n",
        "n_classes = len(train_dataset.class_names)\n",
        "augment_train = partial(preprocess, img_aug=train_img_aug)\n",
        "\n",
        "# # More real-life version\n",
        "# train_gen = (train_dataset\n",
        "#             .cache()\n",
        "#             .shuffle(100)\n",
        "#             .map(augment_train, num_parallel_calls=AUTOTUNE)\n",
        "#             .prefetch(AUTOTUNE)\n",
        "#             .repeat(n_count)\n",
        "#             )\n",
        "\n",
        "# Study-purpose version\n",
        "train_gen = (train_dataset\n",
        "            .map(augment_train, num_parallel_calls=AUTOTUNE)\n",
        "            .repeat(n_count)\n",
        "            .cache()\n",
        "            .shuffle(100)\n",
        "            .prefetch(AUTOTUNE)\n",
        "            )\n",
        "\n",
        "# Validation data generator\n",
        "valid_dataset =  keras.utils.image_dataset_from_directory(\n",
        "      validation_path,\n",
        "      labels='inferred',\n",
        "      label_mode='categorical',\n",
        "      batch_size=1,\n",
        "      image_size=(256, 256)\n",
        "  )\n",
        "augment_valid = partial(preprocess, img_aug=valid_img_aug)\n",
        "\n",
        "valid_gen = (valid_dataset\n",
        "            .map(augment_valid, num_parallel_calls=AUTOTUNE)\n",
        "            .prefetch(AUTOTUNE)\n",
        "            .cache()\n",
        "            )"
      ],
      "metadata": {
        "id": "VxulzFPfkEXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "f35d2401550451752c3a0a87f5de0cea29981590",
        "scrolled": true,
        "id": "iybyrkxB-Wu5"
      },
      "source": [
        "# Check that train data generator is working\n",
        "batch_x, batch_y = next(iter(train_gen.take(1)))\n",
        "for x in batch_x.numpy()[:3]:\n",
        "    plt.imshow(x); plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "78454677508fa70f8b50a1be6abe315d0a3a0a3d",
        "id": "_qXvmGRV-WvE"
      },
      "source": [
        "# Validation generator\n",
        "batch_x, batch_y = next(iter(valid_gen))\n",
        "for x in batch_x:\n",
        "  plt.imshow(x); plt.figure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fclKVw1SO6CS"
      },
      "source": [
        "## Common training parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "481733953766010966ea996db23e7cb6acdc90de",
        "id": "hudCxVmw-WvU"
      },
      "source": [
        "embedding_size = 16  # Try to change this: 64, 128, 512 ?\n",
        "dropout_rate = 0.2  # Try to change this: 0.5, 0.9 ?\n",
        "nb_epochs = 10  # Try to change this: 10, 50, 100 ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tekwNDNVJJzE"
      },
      "source": [
        "## Linear Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojT_LwN_Ksb_"
      },
      "source": [
        "# Set up learning rate\n",
        "LR = 3e-4\n",
        "optimizer = Adam(learning_rate=LR)\n",
        "cce_loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Linear regression model\n",
        "input_shape = target_size + (3,)\n",
        "input_layer = Input(shape=input_shape)\n",
        "# input_layer = keras.layers.Lambda(preprocess_input)(input_layer)  # preprocess with the ImageNet RGB values\n",
        "x = Flatten()(input_layer)\n",
        "output_layer = Dense(n_classes, activation='linear', name='face_embedding')(x)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=cce_loss, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAulh53MMI4V"
      },
      "source": [
        "# Train model\n",
        "hist = model.fit(train_gen,\n",
        "                epochs=nb_epochs,\n",
        "                validation_data=valid_gen,\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLNwtn2Ce1MI"
      },
      "source": [
        "# Evalute model performance with Accuracy, Detection-Error-Tradeoff (DET) curve and  FAR/FRR scores\n",
        "pairs_df = evaluate_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "53e3de4b5f5695c3065268fab018feb128eed2fb",
        "id": "jwroJ7gaCrK6"
      },
      "source": [
        "## Train simple Deep Neural Network classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4b937db1e400bbd9601ecb0cc166fa69ee22d73b",
        "id": "-L-3CrxwCrK8"
      },
      "source": [
        "# Set up learning rate and automatic LR decreasing\n",
        "LR = 3e-4\n",
        "lrate = ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1)\n",
        "optimizer = Adam(learning_rate=LR)\n",
        "cce_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "# Save best model weights\n",
        "save_model = ModelCheckpoint(f'{weights_path}/dnn-weight.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "282c03f0685d0fcf75135a7bb21e9603eb620155",
        "id": "np2I6BiGCrK-"
      },
      "source": [
        "# Create DNN model\n",
        "input_shape = target_size + (3,)\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "x = input_layer\n",
        "x = Flatten()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "\n",
        "x = Dense(64)(x)\n",
        "x = ReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "x = Dense(64)(x)\n",
        "x = ReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "x = Dense(64)(x)\n",
        "x = ReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "x = Dense(64)(x)\n",
        "x = ReLU()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "x = Dense(embedding_size)(x)\n",
        "x = ReLU()(x)\n",
        "x = BatchNormalization(name='face_embedding')(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "output_layer = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "cc93fc22276bb9c07a59054739c2592f4e99398b",
        "id": "MX4JZuU1CrLB"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=cce_loss, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "f328f3a6528f4bb841f1184ad337ea4f9ab647dd",
        "scrolled": true,
        "id": "ywB1x2GeCrLE"
      },
      "source": [
        "# Train model\n",
        "hist = model.fit(train_gen,\n",
        "                epochs=nb_epochs,\n",
        "                validation_data=valid_gen,\n",
        "                callbacks=[lrate, save_model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sZ7HByHCrLH"
      },
      "source": [
        "# Load best weights\n",
        "model.load_weights(f'{weights_path}/dnn-weight.weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyXt03VLCrLK"
      },
      "source": [
        "# Evalute model performance with Accuracy, FAR and FRR scores\n",
        "pairs_df = evaluate_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "53e3de4b5f5695c3065268fab018feb128eed2fb",
        "id": "UHqIMq36-Wva"
      },
      "source": [
        "## Train simple CNN classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4b937db1e400bbd9601ecb0cc166fa69ee22d73b",
        "id": "-k85K8R8-Wvk"
      },
      "source": [
        "# Set up learning rate and automatic LR decreasing\n",
        "LR = 3e-4\n",
        "lrate = ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.5, verbose=1)\n",
        "optimizer = Adam(learning_rate=LR)\n",
        "cce_loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "\n",
        "# Save best model weights\n",
        "save_model = ModelCheckpoint(f'{weights_path}/custom-cnn-weight.weights.h5', monitor='val_loss', save_best_only=True, save_weights_only=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "282c03f0685d0fcf75135a7bb21e9603eb620155",
        "id": "JLwejP52-Wvb"
      },
      "source": [
        "# Create CNN model\n",
        "input_shape = target_size + (3,)\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "x = input_layer\n",
        "\n",
        "x = Conv2D(32, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = Conv2D(32, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = Conv2D(32, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = Conv2D(64, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "x = Conv2D(64, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = Conv2D(64, (3, 3))(x)\n",
        "x = ReLU()(x)\n",
        "x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(embedding_size)(x)\n",
        "x = ReLU()(x)\n",
        "x = BatchNormalization(name='face_embedding')(x)\n",
        "x = Dropout(dropout_rate)(x)\n",
        "\n",
        "output_layer = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[input_layer], outputs=[output_layer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "cc93fc22276bb9c07a59054739c2592f4e99398b",
        "id": "37M-40uS-Wvy"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss=cce_loss, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "f328f3a6528f4bb841f1184ad337ea4f9ab647dd",
        "scrolled": true,
        "id": "88pfBCDq-Wv8"
      },
      "source": [
        "# Train model\n",
        "hist = model.fit(train_gen,\n",
        "                epochs=nb_epochs,\n",
        "                validation_data=valid_gen,\n",
        "                callbacks=[lrate, save_model])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVx69KOLRBIg"
      },
      "source": [
        "# Load best weights\n",
        "model.load_weights(f'{weights_path}/custom-cnn-weight.weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpX-sPw18ime"
      },
      "source": [
        "# Evalute model performance with Accuracy, FAR and FRR scores\n",
        "pairs_df = evaluate_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2cb47bd1e1780b28f5167fd41f88cc6795524d1a",
        "id": "ZuIkLpjk-WzE"
      },
      "source": [
        "# Save outputs as archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "840c2f56a4aa0a9304f3c12984ee966f87155de3",
        "id": "D_I3FGsS-WzE"
      },
      "source": [
        "# Last commands\n",
        "# Save output results to zip\n",
        "!7z a output.7z ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "559ea91221fdc33f4f8b98b0423d8af54a7e8005",
        "id": "ORNGsQid-WzM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkf0WmB8TpTx"
      },
      "source": [
        "!ls \"/gdrive/My Drive/UPEC/Deep Learning Hands-on/Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UKmQSdUTw85"
      },
      "source": [
        "!cp -r weights/ \"/gdrive/My Drive/UPEC/Deep Learning Hands-on/Notebooks\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCOARB6pUHvd"
      },
      "source": [
        "!cp -r \"/gdrive/My Drive/UPEC/Deep Learning Hands-on/Notebooks/weights/\" .\n",
        "!ls weights"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}