{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Comprehensive PyTorch CNN for CIFAR-10\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "# 1. Define transformations for data augmentation and normalization\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors (C x H x W)\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),  # Normalize each channel (R, G, B) to mean=0.5\n",
    "                         (0.5, 0.5, 0.5))  # and standard deviation=0.5\n",
    "])\n",
    "\n",
    "# 2. Load the CIFAR-10 training and testing datasets\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, \n",
    "    batch_size=64,    # Batch Size defined here\n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, \n",
    "    batch_size=64,    # Consistent Batch Size for evaluation\n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# 3. Define the CNN model architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Convolutional Layer 1\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, \n",
    "            out_channels=32, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        # Pooling Layer 1: Max Pooling\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Reduces H and W by half\n",
    "        \n",
    "        # Convolutional Layer 2\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, \n",
    "            out_channels=64, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        # Pooling Layer 2: Average Pooling\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2, padding=0)  # Further reduces H and W by half\n",
    "        \n",
    "        # Convolutional Layer 3\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1\n",
    "        )\n",
    "        # Pooling Layer 3: Max Pooling\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)  # Final downsampling\n",
    "        \n",
    "        # Fully Connected Layer 1\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)  # 64 channels * 4 height * 4 width = 1024 input features\n",
    "        \n",
    "        # Output Layer\n",
    "        self.fc2 = nn.Linear(64, 10)          # 64 input features to 10 classes\n",
    "        \n",
    "        # Activation Function\n",
    "        self.relu = nn.ReLU()                 # ReLU activation function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional Layer 1 -> ReLU -> Pooling Layer 1\n",
    "        x = self.pool1(self.relu(self.conv1(x)))  # Output shape: [batch_size, 32, 16, 16]\n",
    "        \n",
    "        # Convolutional Layer 2 -> ReLU -> Pooling Layer 2\n",
    "        x = self.pool2(self.relu(self.conv2(x)))  # Output shape: [batch_size, 64, 8, 8]\n",
    "        \n",
    "        # Convolutional Layer 3 -> ReLU -> Pooling Layer 3\n",
    "        x = self.pool3(self.relu(self.conv3(x)))  # Output shape: [batch_size, 64, 4, 4]\n",
    "        \n",
    "        # Flatten the tensor into a vector for Fully Connected Layers\n",
    "        x = x.view(-1, 64 * 4 * 4)  # Reshape to [batch_size, 1024]\n",
    "        \n",
    "        # Fully Connected Layer 1 -> ReLU\n",
    "        x = self.relu(self.fc1(x))  # Output shape: [batch_size, 64]\n",
    "        \n",
    "        # Output Layer\n",
    "        x = self.fc2(x)  # Output shape: [batch_size, 10]\n",
    "        \n",
    "        return x\n",
    "\n",
    "# 4. Instantiate the model, define loss function and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Select GPU if available\n",
    "model = CNN().to(device)  # Move model to device\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Define loss function for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Define optimizer with learning rate\n",
    "\n",
    "# 5. Training Loop\n",
    "num_epochs = 10  # Number of epochs for training\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0  # Initialize running loss for the epoch\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    # Use tqdm to create a progress bar for the training loop\n",
    "    for inputs, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
    "        \n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        \n",
    "        outputs = model(inputs)  # Forward pass: compute predicted outputs\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass: compute gradient of the loss w.r.t. model parameters\n",
    "        optimizer.step()  # Update model parameters\n",
    "        \n",
    "        running_loss += loss.item()  # Accumulate loss for the epoch\n",
    "    \n",
    "    # Calculate and print average loss for the epoch\n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print('Finished Training')  # Indicate end of training\n",
    "\n",
    "# 6. Evaluation on Test Data\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to device\n",
    "        \n",
    "        outputs = model(images)  # Forward pass\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Get predictions\n",
    "        \n",
    "        total += labels.size(0)  # Increment total samples\n",
    "        correct += (predicted == labels).sum().item()  # Increment correct predictions\n",
    "\n",
    "test_accuracy = 100 * correct / total  # Calculate accuracy\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")  # Print test accuracy\n",
    "\n",
    "# 7. Saving the Model Checkpoint\n",
    "checkpoint_path = 'cnn_checkpoint.pth'  # Define checkpoint path\n",
    "torch.save(model.state_dict(), checkpoint_path)  # Save model's state dictionary\n",
    "print(\"Model checkpoint saved.\")  # Confirmation message\n",
    "\n",
    "# 8. Loading the Model Checkpoint (Optional)\n",
    "# To load the model later:\n",
    "# model = CNN()  # Initialize the model architecture\n",
    "# model.load_state_dict(torch.load(checkpoint_path))  # Load saved parameters\n",
    "# model.to(device)  # Move to device\n",
    "# model.eval()  # Set to evaluation mode\n",
    "# print(\"Model checkpoint loaded.\")  # Confirmation message\n"
   ],
   "id": "c48fd432f1897598",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Line-by-Line Explanation of PyTorch CNN Code\n",
    "\n",
    "## Imports\n",
    "\n",
    "- **`torch`, `torch.nn`, `torch.optim`:**\n",
    "  - **Purpose:** Core PyTorch libraries essential for building and optimizing neural network models.\n",
    "  - **Usage:** \n",
    "    - `torch` provides the fundamental data structures and operations.\n",
    "    - `torch.nn` offers modules and loss functions to construct neural networks.\n",
    "    - `torch.optim` contains optimization algorithms like SGD and Adam for training models.\n",
    "\n",
    "- **`torchvision`, `torchvision.transforms`:**\n",
    "  - **Purpose:** Utilities for handling image datasets and applying transformations.\n",
    "  - **Usage:**\n",
    "    - `torchvision` provides popular datasets, model architectures, and image transformations.\n",
    "    - `torchvision.transforms` allows for preprocessing steps such as resizing, cropping, normalization, and data augmentation.\n",
    "\n",
    "- **`tqdm`:**\n",
    "  - **Purpose:** Provides progress bars for visualizing training progress.\n",
    "  - **Usage:** Wraps around iterable objects to display real-time progress during training loops, enhancing monitoring and user experience.\n",
    "\n",
    "## Transformations\n",
    "\n",
    "- **`transforms.ToTensor()`:**\n",
    "  - **Function:** Converts images from PIL format to PyTorch tensors.\n",
    "  - **Effect:** Scales pixel values from the range [0, 255] to [0.0, 1.0], preparing them for neural network processing.\n",
    "\n",
    "- **`transforms.Normalize(...)`:**\n",
    "  - **Function:** Normalizes the tensor data.\n",
    "  - **Effect:** Centers the data by subtracting the mean (0.5) and scales it by dividing by the standard deviation (0.5) for each RGB channel. This standardization facilitates faster convergence and improves model performance.\n",
    "\n",
    "## Data Loading\n",
    "\n",
    "- **`torchvision.datasets.CIFAR10(...)`:**\n",
    "  - **Function:** Downloads and loads the CIFAR-10 dataset.\n",
    "  - **Effect:** Applies the defined transformations to the dataset, preparing it for training and testing.\n",
    "\n",
    "- **`torch.utils.data.DataLoader(...)`:**\n",
    "  - **Function:** Creates iterators (`trainloader` and `testloader`) for the training and testing datasets.\n",
    "  - **Parameters:**\n",
    "    - **`batch_size`:** Specifies the number of samples processed in each batch.\n",
    "    - **`shuffle`:** Randomizes the order of data, enhancing training by preventing the model from learning the order of the data.\n",
    "    - **`num_workers`:** Determines the number of subprocesses for data loading, enabling parallel data loading for efficiency.\n",
    "\n",
    "## Model Definition (CNN Class)\n",
    "\n",
    "### `__init__` Method\n",
    "\n",
    "- **Convolutional Layers (`conv1`, `conv2`, `conv3`):**\n",
    "  - **`conv1`:**\n",
    "    - **Input Channels:** 3 (RGB)\n",
    "    - **Output Channels:** 32 (number of filters)\n",
    "    - **Kernel Size:** 3x3\n",
    "    - **Stride:** 1 (moves the filter one pixel at a time)\n",
    "    - **Padding:** 1 (preserves the spatial dimensions of the input)\n",
    "  \n",
    "  - **`conv2`:**\n",
    "    - **Input Channels:** 32\n",
    "    - **Output Channels:** 64\n",
    "    - **Kernel Size:** 3x3\n",
    "    - **Stride:** 1\n",
    "    - **Padding:** 1\n",
    "  \n",
    "  - **`conv3`:**\n",
    "    - **Input Channels:** 64\n",
    "    - **Output Channels:** 64\n",
    "    - **Kernel Size:** 3x3\n",
    "    - **Stride:** 1\n",
    "    - **Padding:** 1\n",
    "\n",
    "- **Pooling Layers (`pool1`, `pool2`, `pool3`):**\n",
    "  - **`pool1` and `pool3`:**\n",
    "    - **Type:** Max Pooling\n",
    "    - **Kernel Size:** 2x2\n",
    "    - **Stride:** 2\n",
    "    - **Padding:** 0\n",
    "    - **Effect:** Reduces spatial dimensions by half (e.g., 32x32 → 16x16).\n",
    "  \n",
    "  - **`pool2`:**\n",
    "    - **Type:** Average Pooling\n",
    "    - **Kernel Size:** 2x2\n",
    "    - **Stride:** 2\n",
    "    - **Padding:** 0\n",
    "    - **Effect:** Further reduces spatial dimensions (e.g., 16x16 → 8x8).\n",
    "\n",
    "- **Fully Connected Layers (`fc1`, `fc2`):**\n",
    "  - **`fc1`:**\n",
    "    - **Input Features:** 64 * 4 * 4 = 1024 (flattened from previous layers)\n",
    "    - **Output Features:** 64\n",
    "  \n",
    "  - **`fc2`:**\n",
    "    - **Input Features:** 64\n",
    "    - **Output Features:** 10 (number of CIFAR-10 classes)\n",
    "\n",
    "- **Activation Function (`relu`):**\n",
    "  - **Function:** Applies the ReLU (Rectified Linear Unit) activation function.\n",
    "  - **Purpose:** Introduces non-linearity after convolutional layers, enabling the network to learn complex patterns.\n",
    "\n",
    "### `forward` Method\n",
    "\n",
    "- **`self.pool1(self.relu(self.conv1(x)))`:**\n",
    "  - **Process:** \n",
    "    - **Convolution (`conv1`)**: Extracts features from the input.\n",
    "    - **Activation (`ReLU`)**: Applies non-linearity.\n",
    "    - **Pooling (`pool1`)**: Reduces spatial dimensions.\n",
    "  - **Output Shape:** `[batch_size, 32, 16, 16]`\n",
    "\n",
    "- **`self.pool2(self.relu(self.conv2(x)))`:**\n",
    "  - **Process:** \n",
    "    - **Convolution (`conv2`)**: Extracts higher-level features.\n",
    "    - **Activation (`ReLU`)**: Applies non-linearity.\n",
    "    - **Pooling (`pool2`)**: Further reduces spatial dimensions.\n",
    "  - **Output Shape:** `[batch_size, 64, 8, 8]`\n",
    "\n",
    "- **`self.pool3(self.relu(self.conv3(x)))`:**\n",
    "  - **Process:** \n",
    "    - **Convolution (`conv3`)**: Extracts complex features.\n",
    "    - **Activation (`ReLU`)**: Applies non-linearity.\n",
    "    - **Pooling (`pool3`)**: Final downsampling.\n",
    "  - **Output Shape:** `[batch_size, 64, 4, 4]`\n",
    "\n",
    "- **`x.view(-1, 64 * 4 * 4)`:**\n",
    "  - **Process:** Reshapes the tensor from `[batch_size, 64, 4, 4]` to `[batch_size, 1024]`.\n",
    "  - **Purpose:** Flattens the multi-dimensional tensor into a 2D tensor suitable for fully connected layers.\n",
    "\n",
    "- **`self.relu(self.fc1(x))`:**\n",
    "  - **Process:** \n",
    "    - **Fully Connected Layer 1 (`fc1`)**: Transforms the flattened tensor.\n",
    "    - **Activation (`ReLU`)**: Applies non-linearity.\n",
    "  - **Output Shape:** `[batch_size, 64]`\n",
    "\n",
    "- **`self.fc2(x)`:**\n",
    "  - **Process:** \n",
    "    - **Output Layer (`fc2`)**: Produces logits for each of the 10 classes.\n",
    "  - **Output Shape:** `[batch_size, 10]`\n",
    "\n",
    "- **`return x`:**\n",
    "  - **Function:** Returns the final output logits for classification.\n",
    "\n",
    "## Model Instantiation and Setup\n",
    "\n",
    "- **`device`:**\n",
    "  - **Function:** Checks if CUDA (GPU) is available.\n",
    "  - **Effect:** Selects GPU for faster computations if available; otherwise, defaults to CPU.\n",
    "\n",
    "- **`model = CNN().to(device)`:**\n",
    "  - **Function:** Instantiates the CNN model and transfers it to the selected device (GPU or CPU).\n",
    "\n",
    "- **`criterion = nn.CrossEntropyLoss()`:**\n",
    "  - **Function:** Defines the loss function suitable for multi-class classification.\n",
    "  - **Effect:** Combines `LogSoftmax` and `NLLLoss` in one single class, computing the loss between predicted logits and true labels.\n",
    "\n",
    "- **`optimizer = optim.Adam(model.parameters(), lr=0.001)`:**\n",
    "  - **Function:** Initializes the Adam optimizer with a learning rate of 0.001.\n",
    "  - **Effect:** Updates model parameters based on computed gradients during training.\n",
    "\n",
    "## Training Loop\n",
    "\n",
    "- **`for epoch in range(num_epochs)`:**\n",
    "  - **Function:** Iterates over the specified number of epochs, representing complete passes through the training dataset.\n",
    "\n",
    "- **`running_loss = 0.0`:**\n",
    "  - **Function:** Initializes a variable to accumulate the loss over the epoch for reporting purposes.\n",
    "\n",
    "- **`model.train()`:**\n",
    "  - **Function:** Sets the model to training mode.\n",
    "  - **Effect:** Enables layers like dropout and batch normalization to behave accordingly during training.\n",
    "\n",
    "- **Batch Loop (`for inputs, labels in tqdm(trainloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")`):**\n",
    "  - **Function:** Iterates over batches of data from the `trainloader`.\n",
    "  - **Effect:** Utilizes `tqdm` to display a progress bar for monitoring training progress.\n",
    "\n",
    "- **Within Each Batch:**\n",
    "  - **`inputs, labels = inputs.to(device), labels.to(device)`:**\n",
    "    - **Function:** Transfers input data and labels to the selected device (GPU or CPU).\n",
    "  \n",
    "  - **`optimizer.zero_grad()`:**\n",
    "    - **Function:** Clears existing gradients to prevent accumulation from previous iterations.\n",
    "  \n",
    "  - **`outputs = model(inputs)`:**\n",
    "    - **Function:** Performs a forward pass through the model to obtain predictions.\n",
    "  \n",
    "  - **`loss = criterion(outputs, labels)`:**\n",
    "    - **Function:** Computes the loss by comparing predictions with true labels.\n",
    "  \n",
    "  - **`loss.backward()`:**\n",
    "    - **Function:** Performs backpropagation to compute gradients of the loss with respect to model parameters.\n",
    "  \n",
    "  - **`optimizer.step()`:**\n",
    "    - **Function:** Updates the model's parameters based on the computed gradients and the optimizer's algorithm.\n",
    "  \n",
    "  - **`running_loss += loss.item()`:**\n",
    "    - **Function:** Accumulates the loss for the current batch to calculate the average loss later.\n",
    "\n",
    "- **After Each Epoch:**\n",
    "  - **`avg_loss = running_loss / len(trainloader)`:**\n",
    "    - **Function:** Calculates the average loss over all batches in the epoch.\n",
    "  \n",
    "  - **`print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")`:**\n",
    "    - **Function:** Prints the average loss for the epoch, providing insight into training progress.\n",
    "\n",
    "## Evaluation on Test Data\n",
    "\n",
    "- **`model.eval()`:**\n",
    "  - **Function:** Sets the model to evaluation mode.\n",
    "  - **Effect:** Disables layers like dropout and batch normalization, ensuring consistent behavior during evaluation.\n",
    "\n",
    "- **Initialize Counters (`correct = 0`, `total = 0`):**\n",
    "  - **Function:** Tracks the number of correct predictions and total samples for accuracy calculation.\n",
    "\n",
    "- **`with torch.no_grad()`:**\n",
    "  - **Function:** Disables gradient computation to optimize memory and computation during evaluation.\n",
    "\n",
    "- **Test Loop (`for data in testloader`):**\n",
    "  - **Function:** Iterates over batches from the `testloader`.\n",
    "\n",
    "- **Within Each Test Batch:**\n",
    "  - **`images, labels = data`:**\n",
    "    - **Function:** Retrieves images and labels from the batch.\n",
    "  \n",
    "  - **`images, labels = images.to(device), labels.to(device)`:**\n",
    "    - **Function:** Transfers data to the selected device.\n",
    "  \n",
    "  - **`outputs = model(images)`:**\n",
    "    - **Function:** Performs a forward pass to obtain predictions.\n",
    "  \n",
    "  - **`_, predicted = torch.max(outputs.data, 1)`:**\n",
    "    - **Function:** Identifies the class with the highest probability as the predicted label.\n",
    "  \n",
    "  - **`total += labels.size(0)`:**\n",
    "    - **Function:** Increments the total number of samples processed.\n",
    "  \n",
    "  - **`correct += (predicted == labels).sum().item()`:**\n",
    "    - **Function:** Increments the count of correctly predicted samples.\n",
    "\n",
    "- **After Test Loop:**\n",
    "  - **`test_accuracy = 100 * correct / total`:**\n",
    "    - **Function:** Calculates the overall test accuracy percentage.\n",
    "  \n",
    "  - **`print(f\"Test Accuracy: {test_accuracy:.2f}%\")`:**\n",
    "    - **Function:** Prints the test accuracy, indicating the model's performance on unseen data.\n",
    "\n",
    "## Saving the Model Checkpoint\n",
    "\n",
    "- **`checkpoint_path = 'cnn_checkpoint.pth'`:**\n",
    "  - **Function:** Defines the file path for saving the model's state dictionary.\n",
    "\n",
    "- **`torch.save(model.state_dict(), checkpoint_path)`:**\n",
    "  - **Function:** Saves the model's parameters to the specified file.\n",
    "  - **Effect:** Serializes the state dictionary containing all learnable parameters (weights and biases).\n",
    "\n",
    "- **`print(\"Model checkpoint saved.\")`:**\n",
    "  - **Function:** Confirms that the model has been successfully saved.\n",
    "\n",
    "---\n"
   ],
   "id": "9df196acb7012d61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the path to save the checkpoint\n",
    "checkpoint_path = 'cnn_checkpoint.pth'\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), checkpoint_path)\n",
    "print(\"Model checkpoint saved.\")\n"
   ],
   "id": "e8ea8e27b5367d5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize a new instance of the model\n",
    "model = CNN()  # Ensure the architecture matches\n",
    "model.to(device)  # Move to device\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(\"Model checkpoint loaded.\")\n"
   ],
   "id": "899af70660df698a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Loading the Model Checkpoint\n",
    "\n",
    "- **`model = CNN()`:**\n",
    "  - **Function:** Initializes a new instance of the CNN model.\n",
    "  - **Purpose:** Creates a fresh model architecture to load the saved parameters into.\n",
    "\n",
    "- **`model.to(device)`:**\n",
    "  - **Function:** Transfers the newly initialized model to the selected device (GPU or CPU).\n",
    "\n",
    "- **`model.load_state_dict(torch.load(checkpoint_path))`:**\n",
    "  - **Function:** Loads the saved parameters into the model.\n",
    "  - **Effect:** Populates the model's weights and biases with the values from the saved state dictionary.\n",
    "\n",
    "- **`model.eval()`:**\n",
    "  - **Function:** Sets the model to evaluation mode.\n",
    "  - **Purpose:** Ensures that layers like dropout and batch normalization behave correctly during inference.\n",
    "\n",
    "- **`print(\"Model checkpoint loaded.\")`:**"
   ],
   "id": "3387b81d11c9b8b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses, callbacks\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "def create_cnn_model(out_channels1=32, out_channels2=64, out_channels3=128):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(out_channels1, (3, 3), strides=1, padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "    model.add(layers.Conv2D(out_channels2, (3, 3), strides=1, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.AveragePooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "    model.add(layers.Conv2D(out_channels3, (3, 3), strides=1, padding='same'))\n",
    "    model.add(layers.ReLU())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = create_cnn_model()\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "              loss=losses.CategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "checkpoint_path = 'cnn_checkpoint.h5'\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                       monitor='val_accuracy',\n",
    "                                       save_best_only=True,\n",
    "                                       verbose=1)\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks=[checkpoint],\n",
    "                    verbose=2)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "model.load_weights(checkpoint_path)\n",
    "model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Model checkpoint loaded.\")\n"
   ],
   "id": "1a2bbeec99b58ecb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Summary Table\n",
    "\n",
    "| **Feature**           | **PyTorch**                                      | **TensorFlow (Keras)**                            |\n",
    "|-----------------------|--------------------------------------------------|----------------------------------------------------|\n",
    "| **Computation Graph** | Dynamic (Eager Execution)                        | Dynamic with optional static graph (via `@tf.function`) |\n",
    "| **Model Definition**  | Imperative (Subclassing `nn.Module`)             | Declarative (Sequential and Functional APIs)        |\n",
    "| **Training Loop**     | Custom loops                                     | Built-in `model.fit()` with options for custom loops |\n",
    "| **Customization**     | Highly flexible and customizable                 | Flexible but more structured                        |\n",
    "| **Data Handling**     | `DataLoader` and `Dataset`                       | `tf.data` API                                       |\n",
    "| **Deployment**        | TorchScript, ONNX                                | TensorFlow Serving, TensorFlow Lite                  |\n",
    "| **Community Focus**   | Research and prototyping                          | Industry and production                              |\n"
   ],
   "id": "cf2d2fd56b6e4ae8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "56c58e3b9ae110e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
